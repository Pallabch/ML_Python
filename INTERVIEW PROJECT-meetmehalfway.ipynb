{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import calendar\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import model_selection\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import ensemble\n",
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Interview.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date of Interview</th>\n",
       "      <th>Client name</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Location</th>\n",
       "      <th>Position to be closed</th>\n",
       "      <th>Nature of Skillset</th>\n",
       "      <th>Interview Type</th>\n",
       "      <th>Name(Cand ID)</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Candidate Current Location</th>\n",
       "      <th>...</th>\n",
       "      <th>Are you clear with the venue details and the landmark.</th>\n",
       "      <th>Has the call letter been shared</th>\n",
       "      <th>Expected Attendance</th>\n",
       "      <th>Observed Attendance</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Unnamed: 23</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "      <th>Unnamed: 26</th>\n",
       "      <th>Unnamed: 27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.02.2015</td>\n",
       "      <td>Hospira</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Production- Sterile</td>\n",
       "      <td>Routine</td>\n",
       "      <td>Scheduled Walkin</td>\n",
       "      <td>Candidate 1</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.02.2015</td>\n",
       "      <td>Hospira</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Production- Sterile</td>\n",
       "      <td>Routine</td>\n",
       "      <td>Scheduled Walkin</td>\n",
       "      <td>Candidate 2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.02.2015</td>\n",
       "      <td>Hospira</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Production- Sterile</td>\n",
       "      <td>Routine</td>\n",
       "      <td>Scheduled Walkin</td>\n",
       "      <td>Candidate 3</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Uncertain</td>\n",
       "      <td>No</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.02.2015</td>\n",
       "      <td>Hospira</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Production- Sterile</td>\n",
       "      <td>Routine</td>\n",
       "      <td>Scheduled Walkin</td>\n",
       "      <td>Candidate 4</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Uncertain</td>\n",
       "      <td>No</td>\n",
       "      <td>Single</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.02.2015</td>\n",
       "      <td>Hospira</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>Production- Sterile</td>\n",
       "      <td>Routine</td>\n",
       "      <td>Scheduled Walkin</td>\n",
       "      <td>Candidate 5</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Uncertain</td>\n",
       "      <td>No</td>\n",
       "      <td>Married</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date of Interview Client name         Industry Location  \\\n",
       "0        13.02.2015     Hospira  Pharmaceuticals  Chennai   \n",
       "1        13.02.2015     Hospira  Pharmaceuticals  Chennai   \n",
       "2        13.02.2015     Hospira  Pharmaceuticals  Chennai   \n",
       "3        13.02.2015     Hospira  Pharmaceuticals  Chennai   \n",
       "4        13.02.2015     Hospira  Pharmaceuticals  Chennai   \n",
       "\n",
       "  Position to be closed Nature of Skillset    Interview Type Name(Cand ID)  \\\n",
       "0   Production- Sterile            Routine  Scheduled Walkin   Candidate 1   \n",
       "1   Production- Sterile            Routine  Scheduled Walkin   Candidate 2   \n",
       "2   Production- Sterile            Routine  Scheduled Walkin   Candidate 3   \n",
       "3   Production- Sterile            Routine  Scheduled Walkin   Candidate 4   \n",
       "4   Production- Sterile            Routine  Scheduled Walkin   Candidate 5   \n",
       "\n",
       "  Gender Candidate Current Location     ...      \\\n",
       "0   Male                    Chennai     ...       \n",
       "1   Male                    Chennai     ...       \n",
       "2   Male                    Chennai     ...       \n",
       "3   Male                    Chennai     ...       \n",
       "4   Male                    Chennai     ...       \n",
       "\n",
       "  Are you clear with the venue details and the landmark.  \\\n",
       "0                                                Yes       \n",
       "1                                                Yes       \n",
       "2                                                NaN       \n",
       "3                                                Yes       \n",
       "4                                                Yes       \n",
       "\n",
       "  Has the call letter been shared Expected Attendance Observed Attendance  \\\n",
       "0                             Yes                 Yes                  No   \n",
       "1                             Yes                 Yes                  No   \n",
       "2                             NaN           Uncertain                  No   \n",
       "3                             Yes           Uncertain                  No   \n",
       "4                             Yes           Uncertain                  No   \n",
       "\n",
       "  Marital Status Unnamed: 23 Unnamed: 24 Unnamed: 25 Unnamed: 26 Unnamed: 27  \n",
       "0         Single         NaN         NaN         NaN         NaN         NaN  \n",
       "1         Single         NaN         NaN         NaN         NaN         NaN  \n",
       "2         Single         NaN         NaN         NaN         NaN         NaN  \n",
       "3         Single         NaN         NaN         NaN         NaN         NaN  \n",
       "4        Married         NaN         NaN         NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26',\n",
      "       'Unnamed: 27'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns[-5:])\n",
    "df[df.columns[-5:]].describe()\n",
    "df.drop(df.columns[-5:],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f=open(\"/home/soham/Desktop/columns\",\"w\")\n",
    "for col in df.columns:\n",
    "    f.write(\"\\\"\"+col+\"\\\"\"+\" : \\\"\\\", \\n\")\n",
    "f.close()\n",
    "\n",
    "f=open(\"/home/soham/Desktop/markdown\",\"w\")\n",
    "for k in dic.keys():\n",
    "    f.write(\"|\"+k+\"|\"+dic[k]+\"|\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dic={\"Date of Interview\" : \"doi\",\n",
    "\"Client name\" : \"cl_nam\",\n",
    "\"Industry\" : \"indus\",\n",
    "\"Location\" : \"cl_loc\",\n",
    "\"Position to be closed\" : \"pos\",\n",
    "\"Nature of Skillset\" : \"skill\",\n",
    "\"Interview Type\" : \"intrvw_typ\",\n",
    "\"Name(Cand ID)\" : \"cand_nam\",\n",
    "\"Gender\" : \"gend\",\n",
    "\"Candidate Current Location\" : \"cand_cur_loc\",\n",
    "\"Candidate Job Location\" : \"cand_j_loc\",\n",
    "\"Interview Venue\" : \"intrvw_ven\",\n",
    "\"Candidate Native location\" : \"cand_nat_loc\",\n",
    "\"Have you obtained the necessary permission to start at the required time\" : \"enq_perm\",\n",
    "\"Hope there will be no unscheduled meetings\" : \"enq_unsch_meet\",\n",
    "\"Can I Call you three hours before the interview and follow up on your attendance for the interview\" : \"enq_call\",\n",
    "\"Can I have an alternative number/ desk number. I assure you that I will not trouble you too much\" : \"enq_num\",\n",
    "\"Have you taken a printout of your updated resume. Have you read the JD and understood the same\" : \"enq_resume\",\n",
    "\"Are you clear with the venue details and the landmark.\" : \"enq_ven\",\n",
    "\"Has the call letter been shared\" : \"enq_call_letter\",\n",
    "\"Expected Attendance\" : \"expc_at\",\n",
    "\"Observed Attendance\" : \"obs_at\",\n",
    "\"Marital Status\" : \"married\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns=col_dic,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Column|Renamed|\n",
    "|---|---|\n",
    "|Date of Interview|doi|\n",
    "|Client name|cl_nam|\n",
    "|Industry|indus|\n",
    "|Location|cl_loc|\n",
    "|Position to be closed|pos|\n",
    "|Nature of Skillset|skill|\n",
    "|Interview Type|intrvw_typ|\n",
    "|Name(Cand ID)|cand_nam|\n",
    "|Gender|gend|\n",
    "|Candidate Current Location|cand_cur_loc|\n",
    "|Candidate Job Location|cand_j_loc|\n",
    "|Interview Venue|intrvw_ven|\n",
    "|Candidate Native location|cand_nat_loc|\n",
    "|Have you obtained the necessary permission to start at the required time|enq_perm|\n",
    "|Hope there will be no unscheduled meetings|enq_unsch_meet|\n",
    "|Can I Call you three hours before the interview and follow up on your attendance for the interview|enq_call|\n",
    "|Can I have an alternative number/ desk number. I assure you that I will not trouble you too much|enq_num|\n",
    "|Have you taken a printout of your updated resume. Have you read the JD and understood the same|enq_resume|\n",
    "|Are you clear with the venue details and the landmark.|enq_ven|\n",
    "|Has the call letter been shared|enq_call_letter|\n",
    "|Expected Attendance|expc_at|\n",
    "|Observed Attendance|obs_at|\n",
    "|Marital Status|married|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "### This section is for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp=df1.copy()\n",
    "#df1=df_temp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in df.columns[1:]:\n",
    "#     print(df_temp[col].value_counts())\n",
    "#     print(\"================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Client Name :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standard Chartered Bank            904\n",
       "Hospira                             75\n",
       "Pfizer                              75\n",
       "Aon Hewitt                          28\n",
       "Flextronics                         23\n",
       "ANZ                                 22\n",
       "Hewitt                              20\n",
       "UST                                 18\n",
       "Prodapt                             17\n",
       "Standard Chartered Bank Chennai     17\n",
       "Astrazeneca                         15\n",
       "Williams Lea                        11\n",
       "Barclays                             5\n",
       "Aon hewitt Gurgaon                   2\n",
       "Woori Bank                           1\n",
       "﻿﻿                                   1\n",
       "Name: cl_nam, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.cl_nam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=[\n",
    "    \"Standard Chartered Bank Chennai\",\n",
    "    \"Hewitt\",\n",
    "    \"Aon hewitt Gurgaon\"\n",
    "]\n",
    "\n",
    "l2=[\n",
    "    \"standard chartered bank\",\n",
    "    \"aon hewitt\",\n",
    "    \"aon hewitt\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standard chartered bank    921\n",
       "hospira                     75\n",
       "pfizer                      75\n",
       "aon hewitt                  50\n",
       "flextronics                 23\n",
       "anz                         22\n",
       "ust                         18\n",
       "prodapt                     17\n",
       "astrazeneca                 15\n",
       "williams lea                11\n",
       "barclays                     5\n",
       "﻿﻿                           1\n",
       "woori bank                   1\n",
       "Name: cl_nam, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.cl_nam.replace(l1,l2,inplace=True)\n",
    "df1.cl_nam=df1.cl_nam.str.lower()\n",
    "df1.cl_nam.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Industry :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BFSI                        949\n",
       "Pharmaceuticals             165\n",
       "IT Products and Services     45\n",
       "Electronics                  23\n",
       "IT Services                  23\n",
       "Telecom                      17\n",
       "IT                           11\n",
       "Name: indus, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.indus.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bfsi               949\n",
      "pharmaceuticals    165\n",
      "it                  79\n",
      "electronics         23\n",
      "telecom             17\n",
      "Name: indus, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.indus.replace([\"IT Products and Services\",\"IT Services\"],[\"IT\",\"IT\"],inplace=True)\n",
    "df1.indus=df1.indus.str.lower()\n",
    "print(df1.indus.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Client Location:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chennai       754\n",
      "Bangalore     292\n",
      "chennai        86\n",
      "Hyderabad      38\n",
      "Gurgaon        33\n",
      "Noida          15\n",
      "- Cochin-       9\n",
      "chennai         3\n",
      "CHENNAI         1\n",
      "Delhi           1\n",
      "Gurgaonr        1\n",
      "Name: cl_loc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.cl_loc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chennai      844\n",
      "bangalore    292\n",
      "hyderabad     38\n",
      "gurgaon       34\n",
      "noida         15\n",
      "cochin         9\n",
      "delhi          1\n",
      "Name: cl_loc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.cl_loc=df1.cl_loc.str.lower().str.strip()\n",
    "df1.cl_loc.replace([\"gurgaonr\",\"- cochin-\"],[\"gurgaon\",\"cochin\"],inplace=True)\n",
    "print(df1.cl_loc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Position to be closed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine                1023\n",
      "Niche                   163\n",
      "Dot Net                  18\n",
      "Trade Finance            11\n",
      "AML                       8\n",
      "Production- Sterile       5\n",
      "Selenium testing          5\n",
      "Name: pos, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.pos.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "routine                1023\n",
      "niche                   163\n",
      "dot net                  18\n",
      "trade finance            11\n",
      "aml                       8\n",
      "selenium testing          5\n",
      "production- sterile       5\n",
      "Name: pos, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.pos=df1.pos.str.lower()\n",
    "print(df1.pos.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Nature of skill set:  \n",
    "too many weird values. Will look at it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA/J2EE/Struts/Hibernate    220\n",
      "Accounting Operations          86\n",
      "Fresher                        86\n",
      "AML/KYC/CDD                    84\n",
      "CDD KYC                        52\n",
      "Name: skill, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1.skill.value_counts()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Interview type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Scheduled Walk In    456\n",
       "Scheduled            371\n",
       "Walkin               189\n",
       "Scheduled Walkin     189\n",
       "Walkin                27\n",
       "Sceduled walkin        1\n",
       "Name: intrvw_typ, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.intrvw_typ.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scheduled walkin    646\n",
       "scheduled           371\n",
       "walkin              216\n",
       "Name: intrvw_typ, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.intrvw_typ=df1.intrvw_typ.str.lower().str.strip()\n",
    "df1.intrvw_typ.replace([\"scheduled walk in\",\"sceduled walkin\"],[\"scheduled walkin\",\"scheduled walkin\"],inplace=True)\n",
    "df1.intrvw_typ.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Name(Cand ID):  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.gend=df1.gend.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Candidate current location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chennai       754\n",
       "Bangalore     292\n",
       "chennai        86\n",
       "Hyderabad      38\n",
       "Gurgaon        34\n",
       "Noida          15\n",
       "- Cochin-       9\n",
       "chennai         3\n",
       "CHENNAI         1\n",
       "Delhi           1\n",
       "Name: cand_cur_loc, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.cand_cur_loc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chennai      844\n",
      "bangalore    292\n",
      "hyderabad     38\n",
      "gurgaon       34\n",
      "noida         15\n",
      "cochin         9\n",
      "delhi          1\n",
      "Name: cand_cur_loc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.cand_cur_loc=df1.cand_cur_loc.str.lower().str.strip()\n",
    "df1.cand_cur_loc.replace([\"- cochin-\"],[\"cochin\"],inplace=True)\n",
    "print(df1.cand_cur_loc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Candidate Job locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chennai          893\n",
       "Bangalore        259\n",
       "Gurgaon           35\n",
       "Visakapatinam     21\n",
       "Noida             15\n",
       "- Cochin-          9\n",
       "Hosur              1\n",
       "Name: cand_j_loc, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.cand_j_loc.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chennai      844\n",
      "bangalore    292\n",
      "hyderabad     38\n",
      "gurgaon       34\n",
      "noida         15\n",
      "cochin         9\n",
      "delhi          1\n",
      "Name: cand_j_loc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.cand_j_loc=df1.cand_cur_loc.str.lower().str.strip()\n",
    "df1.cand_j_loc.replace([\"- cochin-\"],[\"cochin\"],inplace=True)\n",
    "print(df1.cand_j_loc.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Interview venue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chennai       852\n",
       "Bangalore     277\n",
       "Hyderabad      40\n",
       "Gurgaon        35\n",
       "Noida          15\n",
       "- Cochin-       9\n",
       "Hosur           5\n",
       "Name: intrvw_ven, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.intrvw_ven.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chennai      852\n",
      "bangalore    277\n",
      "hyderabad     40\n",
      "gurgaon       35\n",
      "noida         15\n",
      "cochin         9\n",
      "hosur          5\n",
      "Name: intrvw_ven, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.intrvw_ven=df1.intrvw_ven.str.lower().str.strip()\n",
    "df1.intrvw_ven.replace([\"- cochin-\"],[\"cochin\"],inplace=True)\n",
    "print(df1.intrvw_ven.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Candidate native location:  \n",
    "### dont know what to do with this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1=df1.cand_nat_loc.str.lower().str.strip().value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Have you obtained the necessary permission to start at the required time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes               917\n",
       "No                 79\n",
       "Not yet            19\n",
       "Na                  5\n",
       "yes                 4\n",
       "Yet to confirm      4\n",
       "NO                  1\n",
       "Name: enq_perm, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_perm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes    921\n",
      "no     108\n",
      "Name: enq_perm, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.enq_perm=df1.enq_perm.str.lower()\n",
    "df1.enq_perm.replace([\"not yet\",\"na\",\"yet to confirm\"],[\"no\",\"no\",\"no\"],inplace=True)\n",
    "print(df1.enq_perm.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_temp=df1.copy\n",
    "df1.enq_perm.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['enq_perm'].fillna(\"uncertain\",inplace=True)\n",
    "df1.drop(df.index[[1233]], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Hope there will be no unscheduled meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes         954\n",
       "na           20\n",
       "no            6\n",
       "not sure      5\n",
       "cant say      1\n",
       "Name: enq_unsch_meet, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_unsch_meet.str.lower().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes          954\n",
       "no            26\n",
       "uncertain      6\n",
       "Name: enq_unsch_meet, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_unsch_meet=df1.enq_unsch_meet.str.lower()\n",
    "df1.enq_unsch_meet.replace([\"na\",\"cant say\",\"not sure\"],[\"no\",\"uncertain\",\"uncertain\"],inplace=True)\n",
    "df1.enq_unsch_meet.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_unsch_meet.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.enq_unsch_meet.fillna(\"uncertain\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Can I Call you three hours before the interview and follow up on your attendance for the interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes        951\n",
       "Na          20\n",
       "No          10\n",
       "yes          4\n",
       "No Dont      1\n",
       "Name: enq_call, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_call.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    955\n",
       "no      31\n",
       "Name: enq_call, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_call=df1.enq_call.str.lower()\n",
    "df1.enq_call.replace([\"na\",\"no dont\"],[\"no\",\"no\"],inplace=True)\n",
    "df1.enq_call.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.enq_call.fillna(\"uncertain\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Can I have an alternative number/ desk number. I assure you that I will not trouble you too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes                          936\n",
       "No                            27\n",
       "Na                            19\n",
       "No I have only thi number      2\n",
       "yes                            1\n",
       "na                             1\n",
       "Name: enq_num, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes    937\n",
      "no      49\n",
      "Name: enq_num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.enq_num=df1.enq_num.str.lower()\n",
    "df1.enq_num.replace([\"na\",\"no i have only thi number\"],[\"no\",\"no\"],inplace=True)\n",
    "print(df1.enq_num.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.enq_num.fillna(\"uncertain\",inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Have you taken a printout of your updated resume. Have you read the JD and understood the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes                      940\n",
       "Na                        19\n",
       "No                        16\n",
       "Not Yet                    4\n",
       "yes                        2\n",
       "Not yet                    2\n",
       "na                         1\n",
       "No- will take it soon      1\n",
       "Name: enq_resume, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_resume.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    942\n",
       "no      43\n",
       "Name: enq_resume, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_resume=df1.enq_resume.str.lower()\n",
    "df1.enq_resume.replace([\"na\",\"not yet\",\"no- will take it soon\"],[\"no\",\"no\",\"no\"],inplace=True)\n",
    "df1.enq_resume.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.enq_resume.fillna(\"uncertain\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Are you clear with the venue details and the landmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes                    946\n",
       "Na                      19\n",
       "No                      14\n",
       "yes                      2\n",
       "No- I need to check      2\n",
       "na                       1\n",
       "no                       1\n",
       "Name: enq_ven, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_ven.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes    948\n",
      "no      37\n",
      "Name: enq_ven, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.enq_ven=df1.enq_ven.str.lower()\n",
    "df1.enq_ven.replace([\"na\",\"no- i need to check\"],[\"no\",\"no\"],inplace=True)\n",
    "print(df1.enq_ven.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.enq_ven.fillna(\"uncertain\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Has the call letter been shared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes               932\n",
       "Na                 19\n",
       "No                 17\n",
       "Not Sure            8\n",
       "Need To Check       3\n",
       "yes                 2\n",
       "Not yet             2\n",
       "Not sure            1\n",
       "Yet to Check        1\n",
       "na                  1\n",
       "Havent Checked      1\n",
       "no                  1\n",
       "Name: enq_call_letter, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_call_letter.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes          934\n",
      "no            40\n",
      "uncertain     14\n",
      "Name: enq_call_letter, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.enq_call_letter=df1.enq_call_letter.str.lower()\n",
    "df1.enq_call_letter.replace([\"na\",\"not yet\",\"not sure\",\"havent checked\",\"yet to check\",\"need to check\"],[\"no\",\"no\",\"uncertain\",\"uncertain\",\"uncertain\",\"uncertain\"],inplace=True)\n",
    "print(df1.enq_call_letter.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes          934\n",
       "uncertain    259\n",
       "no            40\n",
       "Name: enq_call_letter, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.enq_call_letter.fillna(\"uncertain\",inplace=True)\n",
    "df1.enq_call_letter.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Expected Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes          882\n",
       "Uncertain    250\n",
       "No            59\n",
       "NO            34\n",
       "yes            1\n",
       "10.30 Am       1\n",
       "11:00 AM       1\n",
       "Name: expc_at, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.expc_at.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes          885\n",
      "uncertain    250\n",
      "no            93\n",
      "Name: expc_at, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.expc_at=df1.expc_at.str.lower()\n",
    "df1.expc_at.replace([\"11:00 am\",\"10.30 am\"],[\"yes\",\"yes\"],inplace=True)\n",
    "print(df1.expc_at.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.expc_at.fillna(\"uncertain\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Observed Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes     701\n",
       "No      401\n",
       "yes      81\n",
       "NO       35\n",
       "no        7\n",
       "No        6\n",
       "no        1\n",
       "yes       1\n",
       "Name: obs_at, dtype: int64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.obs_at.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes    783\n",
      "no     450\n",
      "Name: obs_at, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.obs_at=df1.obs_at.str.lower().str.strip()\n",
    "print(df1.obs_at.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## Marital Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Single     767\n",
       "Married    466\n",
       "Name: married, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.married.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single     767\n",
      "married    466\n",
      "Name: married, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df1.married=df1.married.str.lower()\n",
    "print(df1.married.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "## DATE OF INTERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is used to format the dates \n",
    "def clean_date(date):\n",
    "    date = date.str.strip()\n",
    "    date = date.str.split(\"&\").str[0]\n",
    "    date = date.str.replace('–', '/')\n",
    "    date = date.str.replace('.', '/')\n",
    "    date = date.str.replace('Apr', '04')\n",
    "    date = date.str.replace('-', '/')\n",
    "    date = date.str.replace(' ', '/')\n",
    "    date = date.str.replace('//+', '/')\n",
    "    return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modeling_df = modeling_df[modeling_df['date'] < '2018-01-01'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['doi'] = clean_date(df1['doi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df1.doi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To make all the values in the same format of date time to get the day of interview and the month of interview\n",
    "df1['year'] = df1['doi'].str.split(\"/\").str[2]\n",
    "df1['day'] = df1['doi'].str.split(\"/\").str[0]\n",
    "df1['month'] = df1['doi'].str.split(\"/\").str[1]\n",
    "df1['year'].replace(['16', '15'], ['2016', '2015'], inplace = True)\n",
    "df1['date'] = pd.to_datetime(pd.DataFrame({'year': df1['year'],\n",
    "                                            'month': df1['month'],\n",
    "                                            'day': df1['day']}), format = '%Y-%m-%d')\n",
    "df1.drop(['year', 'month', 'day'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt=df1['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[]\n",
    "for i in range(len(dt)):\n",
    "    ls.append(dt[i].month)\n",
    "df1['month']=ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=[]\n",
    "for i in range(len(dt)):\n",
    "    ls.append(dt[i].weekday()+1)\n",
    "df1['day']=ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(columns=['doi','date','skill'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cl_nam   0\n",
      "indus   0\n",
      "cl_loc   0\n",
      "pos   0\n",
      "intrvw_typ   0\n",
      "cand_nam   0\n",
      "gend   0\n",
      "cand_cur_loc   0\n",
      "cand_j_loc   0\n",
      "intrvw_ven   0\n",
      "cand_nat_loc   0\n",
      "enq_perm   0\n",
      "enq_unsch_meet   0\n",
      "enq_call   0\n",
      "enq_num   0\n",
      "enq_resume   0\n",
      "enq_ven   0\n",
      "enq_call_letter   0\n",
      "expc_at   0\n",
      "obs_at   0\n",
      "married   0\n",
      "month   0\n",
      "day   0\n"
     ]
    }
   ],
   "source": [
    "for col in df1.columns:\n",
    "    print(col,\" \",df1[col].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df1.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "---  \n",
    "# Cleaned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1233 entries, 0 to 1232\n",
      "Data columns (total 23 columns):\n",
      "cl_nam             1233 non-null object\n",
      "indus              1233 non-null object\n",
      "cl_loc             1233 non-null object\n",
      "pos                1233 non-null object\n",
      "intrvw_typ         1233 non-null object\n",
      "cand_nam           1233 non-null object\n",
      "gend               1233 non-null object\n",
      "cand_cur_loc       1233 non-null object\n",
      "cand_j_loc         1233 non-null object\n",
      "intrvw_ven         1233 non-null object\n",
      "cand_nat_loc       1233 non-null object\n",
      "enq_perm           1233 non-null object\n",
      "enq_unsch_meet     1233 non-null object\n",
      "enq_call           1233 non-null object\n",
      "enq_num            1233 non-null object\n",
      "enq_resume         1233 non-null object\n",
      "enq_ven            1233 non-null object\n",
      "enq_call_letter    1233 non-null object\n",
      "expc_at            1233 non-null object\n",
      "obs_at             1233 non-null object\n",
      "married            1233 non-null object\n",
      "month              1233 non-null int64\n",
      "day                1233 non-null int64\n",
      "dtypes: int64(2), object(21)\n",
      "memory usage: 271.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cl_nam</th>\n",
       "      <th>indus</th>\n",
       "      <th>cl_loc</th>\n",
       "      <th>pos</th>\n",
       "      <th>intrvw_typ</th>\n",
       "      <th>cand_nam</th>\n",
       "      <th>gend</th>\n",
       "      <th>cand_cur_loc</th>\n",
       "      <th>cand_j_loc</th>\n",
       "      <th>intrvw_ven</th>\n",
       "      <th>...</th>\n",
       "      <th>enq_call</th>\n",
       "      <th>enq_num</th>\n",
       "      <th>enq_resume</th>\n",
       "      <th>enq_ven</th>\n",
       "      <th>enq_call_letter</th>\n",
       "      <th>expc_at</th>\n",
       "      <th>obs_at</th>\n",
       "      <th>married</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hospira</td>\n",
       "      <td>pharmaceuticals</td>\n",
       "      <td>chennai</td>\n",
       "      <td>production- sterile</td>\n",
       "      <td>scheduled walkin</td>\n",
       "      <td>Candidate 1</td>\n",
       "      <td>male</td>\n",
       "      <td>chennai</td>\n",
       "      <td>chennai</td>\n",
       "      <td>hosur</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>single</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hospira</td>\n",
       "      <td>pharmaceuticals</td>\n",
       "      <td>chennai</td>\n",
       "      <td>production- sterile</td>\n",
       "      <td>scheduled walkin</td>\n",
       "      <td>Candidate 2</td>\n",
       "      <td>male</td>\n",
       "      <td>chennai</td>\n",
       "      <td>chennai</td>\n",
       "      <td>hosur</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>single</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hospira</td>\n",
       "      <td>pharmaceuticals</td>\n",
       "      <td>chennai</td>\n",
       "      <td>production- sterile</td>\n",
       "      <td>scheduled walkin</td>\n",
       "      <td>Candidate 3</td>\n",
       "      <td>male</td>\n",
       "      <td>chennai</td>\n",
       "      <td>chennai</td>\n",
       "      <td>hosur</td>\n",
       "      <td>...</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>no</td>\n",
       "      <td>single</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hospira</td>\n",
       "      <td>pharmaceuticals</td>\n",
       "      <td>chennai</td>\n",
       "      <td>production- sterile</td>\n",
       "      <td>scheduled walkin</td>\n",
       "      <td>Candidate 4</td>\n",
       "      <td>male</td>\n",
       "      <td>chennai</td>\n",
       "      <td>chennai</td>\n",
       "      <td>hosur</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>no</td>\n",
       "      <td>single</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hospira</td>\n",
       "      <td>pharmaceuticals</td>\n",
       "      <td>chennai</td>\n",
       "      <td>production- sterile</td>\n",
       "      <td>scheduled walkin</td>\n",
       "      <td>Candidate 5</td>\n",
       "      <td>male</td>\n",
       "      <td>chennai</td>\n",
       "      <td>chennai</td>\n",
       "      <td>hosur</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>uncertain</td>\n",
       "      <td>no</td>\n",
       "      <td>married</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    cl_nam            indus   cl_loc                  pos        intrvw_typ  \\\n",
       "0  hospira  pharmaceuticals  chennai  production- sterile  scheduled walkin   \n",
       "1  hospira  pharmaceuticals  chennai  production- sterile  scheduled walkin   \n",
       "2  hospira  pharmaceuticals  chennai  production- sterile  scheduled walkin   \n",
       "3  hospira  pharmaceuticals  chennai  production- sterile  scheduled walkin   \n",
       "4  hospira  pharmaceuticals  chennai  production- sterile  scheduled walkin   \n",
       "\n",
       "      cand_nam  gend cand_cur_loc cand_j_loc intrvw_ven ...   enq_call  \\\n",
       "0  Candidate 1  male      chennai    chennai      hosur ...        yes   \n",
       "1  Candidate 2  male      chennai    chennai      hosur ...        yes   \n",
       "2  Candidate 3  male      chennai    chennai      hosur ...  uncertain   \n",
       "3  Candidate 4  male      chennai    chennai      hosur ...         no   \n",
       "4  Candidate 5  male      chennai    chennai      hosur ...        yes   \n",
       "\n",
       "     enq_num enq_resume    enq_ven enq_call_letter    expc_at obs_at  married  \\\n",
       "0        yes        yes        yes             yes        yes     no   single   \n",
       "1        yes        yes        yes             yes        yes     no   single   \n",
       "2  uncertain  uncertain  uncertain       uncertain  uncertain     no   single   \n",
       "3        yes         no        yes             yes  uncertain     no   single   \n",
       "4         no        yes        yes             yes  uncertain     no  married   \n",
       "\n",
       "  month day  \n",
       "0     2   5  \n",
       "1     2   5  \n",
       "2     2   5  \n",
       "3     2   5  \n",
       "4     2   5  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop('cand_nam',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.copy()\n",
    "def t(col):\n",
    "    j=1\n",
    "    dic={}\n",
    "    for i in df2[col].value_counts().index:\n",
    "        dic[i]=j\n",
    "        j+=1\n",
    "    df2[col].replace(dic,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df2.columns:\n",
    "    if(col=='month' or col=='day'):\n",
    "        continue\n",
    "    t(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohel = df2.drop(['obs_at','expc_at'],axis=1).columns.tolist()\n",
    "df3 = pd.get_dummies(df2, prefix=ohel, columns=ohel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "---  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns.value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df3.drop(['obs_at','expc_at'],axis=1)\n",
    "y = df3['obs_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholder = VarianceThreshold(threshold=.22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high_variance = thresholder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pos_6', 'intrvw_ven_6', 'enq_call_letter_2', 'enq_call_letter_3',\n",
       "       'day_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.columns[thresholder.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_scores = feature_selection.mutual_info_classif(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enq_perm_3',\n",
       " 'enq_perm_1',\n",
       " 'enq_call_1',\n",
       " 'enq_num_1',\n",
       " 'enq_resume_1',\n",
       " 'enq_ven_2',\n",
       " 'enq_resume_2',\n",
       " 'enq_num_2',\n",
       " 'cand_nat_loc_43',\n",
       " 'gend_1']"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "micc = []\n",
    "for score, fname in sorted(zip(feature_scores, X.columns.tolist()), reverse=True)[:10]:\n",
    "    micc += [fname]\n",
    "micc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['enq_perm_1', 'enq_num_1', 'enq_resume_1'], dtype='object')"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = df3[micc]\n",
    "thresholder2 = VarianceThreshold(threshold=0.18)\n",
    "X_high_variance2 = thresholder2.fit_transform(X2)\n",
    "X2.columns[thresholder2.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = df3[X2.columns[thresholder2.get_support(indices=True)].tolist()+df3.columns[thresholder.get_support(indices=True)].tolist()]\n",
    "X4 = df3[df3.columns[thresholder.get_support(indices=True)].tolist()]\n",
    "X5 = df3[X2.columns[thresholder2.get_support(indices=True)].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "---  \n",
    "## Function common to all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printresult(actual,predicted):\n",
    "    confmatrix=metrics.confusion_matrix(actual,predicted)\n",
    "    accscore=metrics.accuracy_score(actual,predicted)\n",
    "    precscore=metrics.precision_score(actual,predicted)\n",
    "    recscore=metrics.recall_score(actual,predicted)\n",
    "    print(confmatrix)\n",
    "    print(\"accuracy : {:.4f}\".format(accscore))\n",
    "    print(\"precision : {:.4f}\".format(precscore))\n",
    "    print(\"recall : {:.4f}\".format(recscore))\n",
    "    print(\"f1-score : {:.4f}\".format(metrics.f1_score(actual,predicted)))\n",
    "    print(\"AUC : {:.4f}\".format(metrics.roc_auc_score(actual,predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "---  \n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111  18]\n",
      " [ 24  32]]\n",
      "accuracy : 0.7730\n",
      "precision : 0.8222\n",
      "recall : 0.8605\n",
      "f1-score : 0.8409\n",
      "AUC : 0.7159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtrain3,Xtest3,ytrain3,ytest3=model_selection.train_test_split(X3,y,test_size=.15,random_state=210)\n",
    "model1=linear_model.LogisticRegression()\n",
    "model1.fit(Xtrain3,ytrain3)\n",
    "predict_test1=model1.predict(Xtest3)\n",
    "printresult(ytest3,predict_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111  18]\n",
      " [ 28  28]]\n",
      "accuracy : 0.7514\n",
      "precision : 0.7986\n",
      "recall : 0.8605\n",
      "f1-score : 0.8284\n",
      "AUC : 0.6802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtrain4,Xtest4,ytrain4,ytest4=model_selection.train_test_split(X4,y,test_size=.15,random_state=210)\n",
    "model14=linear_model.LogisticRegression()\n",
    "model14.fit(Xtrain4,ytrain)\n",
    "predict_test14=model14.predict(Xtest4)\n",
    "printresult(ytest4,predict_test14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112  17]\n",
      " [ 25  31]]\n",
      "accuracy : 0.7730\n",
      "precision : 0.8175\n",
      "recall : 0.8682\n",
      "f1-score : 0.8421\n",
      "AUC : 0.7109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "Xtrain5,Xtest5,ytrain5,ytest5=model_selection.train_test_split(X5,y,test_size=.15,random_state=210)\n",
    "model15=linear_model.LogisticRegression()\n",
    "model15.fit(Xtrain5,ytrain)\n",
    "predict_test15=model15.predict(Xtest5)\n",
    "printresult(ytest5,predict_test15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df3[X3.columns.tolist()+['obs_at']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "---  \n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111  18]\n",
      " [ 25  31]]\n",
      "accuracy : 0.7676\n",
      "precision : 0.8162\n",
      "recall : 0.8605\n",
      "f1-score : 0.8377\n",
      "AUC : 0.7070\n"
     ]
    }
   ],
   "source": [
    "model2=naive_bayes.BernoulliNB()\n",
    "model2.fit(Xtrain,ytrain)\n",
    "predict_test2=model2.predict(Xtest)\n",
    "printresult(ytest,predict_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "---  \n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[114  15]\n",
      " [ 26  30]]\n",
      "accuracy : 0.7784\n",
      "precision : 0.8143\n",
      "recall : 0.8837\n",
      "f1-score : 0.8476\n",
      "AUC : 0.7097\n"
     ]
    }
   ],
   "source": [
    "model3=ensemble.RandomForestClassifier(n_estimators=1000)\n",
    "model3.fit(Xtrain,ytrain)\n",
    "predict_test3=model3.predict(Xtest)\n",
    "printresult(ytest,predict_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
